概念：注意指意识对一定信息或对象的指向与集中的过程，具有选择性和集中性等特点，是一切心理过程得以产生和进行的必不可少的心理属性

分类：

+ 自然语言：句子级或篇章级中单词和单词之间因为上下文而共同出现的概率
+ 图像分析：在一定视觉区域中视觉子块之间的空间分布模式
+ 机器翻译：输入源语言单词和输出目标语言单词之间的关联

Transformer模型：

![image.png](https://s2.loli.net/2023/11/20/eMLRZ9lEK68aYCP.png)
单词内嵌向量$w_i$

查询向量$q_i=W^q\times w_i$

键向量$k_i=W^k\times w_i$

值向量$v_i=W^v\times w_i$

目的：挖掘单词$w_i$与其他单词在句子中因为上下文(context)关联而具有的自注意力取值大小

步骤：

1. 计算$w_3$所对应的查询向量与其它向量键向量的点积$a_{3i}=q_3\cdot k_i$
2. 对$a_3$通过softmax进行归一化，得到$a'_{3i}$
3. $a_{3i}'$乘以每个单词$w_i$所对应的值向量$v_i$
4. 对3所得的结果求和

多头注意力：从更多角度来挖掘某个单词与其他单词之间的概率关联
